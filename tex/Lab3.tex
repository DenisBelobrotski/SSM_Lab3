\documentclass[12pt]{article}
\usepackage[russian]{babel}
\usepackage{indentfirst}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage[left=2cm, right=2cm, top=2cm, bottom=2cm, bindingoffset=0cm]
{geometry}

\begin{document}

\textbf{Белоброцкий Денис 4 курс 5 группа}
\\
\begin{center}
	{\Large Лабораторная работа №3}
\end{center} 
\begin{center}
	{\large \textbf{Моделирование непрерывных СВ}}
\end{center} 
\begin{center}
	Вариант 2
\end{center}

	\section*{Постановка задачи}
	\par Осуществить моделирование $ n = 1000 $ реализаций СВ из нормального закона распределения $ N(m, s^2) $ с заданными параметрами. Смоделировать $ n = 1000 $ СВ с логнормальным распределением и распределением Коши. Найти несмещённые оценки математического ожидания и дисперсии. Проверить точность моделирования обоих распределений с помощью $ \chi^2 $-критерия Пирсона с уровнем значимости $ \varepsilon = 0.05 $ и с помощью критерия Колмогорова. А также проверить, что вероятность ошибки $ I $ рода стремиться к $ 0.05 $.
	\section*{Теория}
	\par \textbf{Моделирование нормального закона распределения} 
	\par Для моделирования нормального закона распределения воспользуемся преобразованием Бокса-Мюллер. Пусть $ r $ и $ \varphi $ независимые случайные величины, равномерно распределённые в интервале $ (0,1] $. Вычислим $ z_0 $ и $ z_1 $ по формулам: \par
	$$ z_0 = \cos(2 \pi \varphi) \sqrt{-2lnr} $$
	$$ z_1 = \sin(2 \pi \varphi) \sqrt{-2lnr} $$
	\\ Теперь подставив $ z_0 $ и $ z_1 $ вместо $ z $ в формулу $ \xi = m + \sqrt{s} z $ мы получим две случайных величины имеющих нормальное распределение.
	\par \textbf{Моделирование логнормального распределения}	
	\par Для моделирования логнормального распределения воспользуемся следующим соотношением:
	$$ X \sim N(\mu, \sigma^2), \exp(X) \sim LN(\mu, \sigma^2) $$ 
	\par Получим следующую формулу:
	$$ \xi = \exp(\mu + \sigma x)$$
	\par Где $ x $ случайная величина с нормальным распределением.
	\par \textbf{Моделирование распределения Коши}
	\par Для моделирования распределения Коши воспользуемся следующим соотношением:
	$$  X \sim U(a, b), \tg(\pi(X-\frac{1}{2})) \sim C(a, b) $$ 
	\par Получим следующую формулу:
	$$ \xi = a + b \tg(2 \pi x)$$
	\par Где $ x $ случайная величина с равномерным распределением.
	\pagebreak
	
\par \textbf{Критерий Колмогорова}
	\par Данный критерий позволяет осуществить проверку гипотез в условиях, когда функция распределения $ F_{0}(x) $ модельного закона известна полностью, то есть не зависит от неизвестных параметров. Он основан на анализе мер уклонения эмпирической и модельной функций распределения.
	\par Эмпирическая функция распределения по случайной выборке $ X = \lbrace x_{1},...,x_{n} \rbrace $ реализаций СВ $ \xi $ определяется по формуле:
$$
F_{n}(x) = \frac{1}{n} \sum\limits_{i=1}^{n} I_{[-\infty, x]} (x_{i}),\: I_{[-\infty, x]} (x_{i}) = 
	\begin{cases}
			1, x_{i} \leq x, \\
			0, x_{i} > x.
	\end{cases}
$$
	\par Введём статистику
$$
D = \sup_{x \in R} \mid F_{0}(x) - F_{n}(x) \mid \in [0, 1]
$$
называемую расстоянием Колмогорова между $ F_{0}(x) $ и $ F_{n}(x) $.
	\par Принятие гипотезы происходит следующим образом:
$$
	\begin{cases}
			H_{0},\; \sqrt[]{n} D < \Delta, \\
			H_{1},\; \sqrt[]{n} D \geq \Delta.
	\end{cases} 
$$
	\par Порог $ \Delta = K^{-1}(1 - \varepsilon) $ - квантиль уровня $ (1 - \varepsilon) $ распределения Колмогорова, $ \varepsilon $ - задаваемый пользователем уровень значимости. Где $$ K(y) = 1 - 2 \sum_{j=1}^{\tau} (-1)^{j - 1} \exp(-2 j^2 y^2),\; y\geq 0 $$	
	
	\par \textbf{Критерий Пирсона}
	\par Данный критерий широко используется в задачах статистического анализа данных для проверки соответствия экспериментальных данных заданному модельному непрерывному или дискретному закону распределения, определяемому функцией распределения $ F_{0}(x)=F_{0}(x, \theta_{0}) $. 
	\par Гипотетические вероятности попадания значений $ \xi $ в ячейки гистограммы при истинной гипотезе $ H_{0} $ и полностью заданной функции $ F_{0}(x) $ равны:
$$
p_k = P \lbrace \xi \in [x_{k - 1}, x_k) \rbrace = F_0 (x_k) - F_0 (x_{k - 1}),
$$
где $ \lbrace x_l \rbrace (l = \overline{0, K}) $ - границы ячеек гистограммы. 
	\par Статистика критерия проверки гипотез имеет вид:
	$$ \chi^2 = \sum_{k = 1}^K \frac{(\nu_k - np_k)^2}{np_k} \geq 0 $$
	\par Данная статистика характеризует взвешенную сумму квадратов отклонений частот $ \lbrace \nu_k \rbrace $ от гипотетических значений $ \lbrace np_k \rbrace $. Чем больше $ \chi^2 $ , тем “сильнее” выборка $ X $ не согласуется с $ H_0 $. 
	\par Статистика $ (1) $ предполагает, что гипотеза $ H_0 $ верна, $ \chi^2 $ - распределение с $ K - 1 $ степенями свободы.
	\par Принятие гипотезы происходит следующим образом:
$$ 
	\begin{cases}
			H_{0},\; \chi^2 < \Delta, \\
			H_{1},\; \chi^2 \geq \Delta,
	\end{cases} 
$$
	\\где $ \Delta = 1 - F(\chi^2) $, $ F(\chi^2) $ - значение ф-ции распределения статистики $ (1) $ со степенью свободы $ K - 1 $. Значение это вычисляется с помощью какой-то функции, либо берется табличным. 

\end{document}